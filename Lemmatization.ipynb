{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3033376f",
   "metadata": {},
   "source": [
    "##### 1. wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbaf84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kites ---> kite\n",
      "babies ---> baby\n",
      "dogs ---> dog\n",
      "flying ---> flying\n",
      "smiling ---> smiling\n",
      "driving ---> driving\n",
      "died ---> died\n",
      "tried ---> tried\n",
      "feet ---> foot\n",
      "laid ---> laid\n",
      "sat ---> sat\n",
      "seen ---> seen\n",
      "mice ---> mouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet') ## Convert words to their base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create WordNetLemmatizer object\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# single word lemmatization\n",
    "list1 = ['kites', 'babies', 'dogs', 'flying', 'smiling', \n",
    "\t\t'driving', 'died', 'tried', 'feet', 'laid', 'sat','seen', 'mice']\n",
    "for words in list1:\n",
    "\tprint(words + \" ---> \" + wnl.lemmatize(words))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064f957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'is', 'sitting', 'with', 'the', 'bats', 'on', 'the', 'striped', 'mat', 'under', 'many', 'flying', 'geese']\n",
      "the cat is sitting with the bat on the striped mat under many flying goose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt') # This package is for converting a string to tokens\n",
    "# sentence lemmatization examples\n",
    "string = 'the cat is sitting with the bats on the striped mat under many flying geese'\n",
    "\n",
    "# Converting String into tokens\n",
    "list2 = nltk.word_tokenize(string)\n",
    "print(list2)\n",
    "\n",
    "lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2])\n",
    "\n",
    "print(lemmatized_string) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f53f8",
   "metadata": {},
   "source": [
    "##### 2. Wordnet Lemmatizer (with POS tag) Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86480e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function to lemmatize each word with its POS tag\n",
    "\n",
    "# POS_TAGGER_FUNCTION : TYPE 1\n",
    "def pos_tagger(nltk_tag):\n",
    "\tif nltk_tag.startswith('J'):\n",
    "\t\treturn wordnet.ADJ\n",
    "\telif nltk_tag.startswith('V'):\n",
    "\t\treturn wordnet.VERB\n",
    "\telif nltk_tag.startswith('N'):\n",
    "\t\treturn wordnet.NOUN\n",
    "\telif nltk_tag.startswith('R'):\n",
    "\t\treturn wordnet.ADV\n",
    "\telse:\t\t \n",
    "\t\treturn None\n",
    "\n",
    "sentence = 'the cat is sitting with the bats on the striped mat under many badly flying geese'\n",
    "\n",
    "# tokenize the sentence and find the POS tag for each token\n",
    "pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence)) \n",
    "\n",
    "print(pos_tagged)\n",
    "#>[('the', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('with', 'IN'), \n",
    "# ('the', 'DT'), ('bats', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('striped', 'JJ'), \n",
    "# ('mat', 'NN'), ('under', 'IN'), ('many', 'JJ'), ('flying', 'VBG'), ('geese', 'JJ')]\n",
    "\n",
    "# As you may have noticed, the above pos tags are a little confusing.\n",
    "\n",
    "# we use our own pos_tagger function to make things simpler to understand.\n",
    "wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "print(wordnet_tagged)\n",
    "#>[('the', None), ('cat', 'n'), ('is', 'v'), ('sitting', 'v'), ('with', None), \n",
    "# ('the', None), ('bats', 'n'), ('on', None), ('the', None), ('striped', 'a'), \n",
    "# ('mat', 'n'), ('under', None), ('many', 'a'), ('flying', 'v'), ('geese', 'a')]\n",
    "\n",
    "lemmatized_sentence = []\n",
    "for word, tag in wordnet_tagged:\n",
    "\tif tag is None:\n",
    "\t\t# if there is no available tag, append the token as is\n",
    "\t\tlemmatized_sentence.append(word)\n",
    "\telse:\t \n",
    "\t\t# else use the tag to lemmatize the token\n",
    "\t\tlemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "\n",
    "print(lemmatized_sentence)\n",
    "#> the cat can be sit with the bat on the striped mat under many fly geese\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
